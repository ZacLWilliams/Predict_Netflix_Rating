{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train_dataset.csv')\n",
    "test = pd.read_csv('test_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_countvec/train_countvec_features_actor_1_name.npy\n",
      "2063\n",
      "features_countvec/train_countvec_features_actor_2_name.npy\n",
      "2919\n",
      "features_countvec/train_countvec_features_director_name.npy\n",
      "2113\n",
      "features_doc2vec/train_doc2vec_features_genre.npy\n",
      "100\n",
      "features_doc2vec/train_doc2vec_features_plot_keywords.npy\n",
      "100\n",
      "features_fasttext/train_fasttext_title_embeddings.npy\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "names_train = ['features_countvec/train_countvec_features_actor_1_name.npy', 'features_countvec/train_countvec_features_actor_2_name.npy', \n",
    "               'features_countvec/train_countvec_features_director_name.npy', 'features_doc2vec/train_doc2vec_features_genre.npy',\n",
    "               'features_doc2vec/train_doc2vec_features_plot_keywords.npy', 'features_fasttext/train_fasttext_title_embeddings.npy']\n",
    "names_test = ['features_countvec/test_countvec_features_actor_1_name.npy', 'features_countvec/test_countvec_features_actor_2_name.npy', \n",
    "               'features_countvec/test_countvec_features_director_name.npy', 'features_doc2vec/test_doc2vec_features_genre.npy',\n",
    "               'features_doc2vec/test_doc2vec_features_plot_keywords.npy', 'features_fasttext/test_fasttext_title_embeddings.npy']\n",
    "\n",
    "for name in names_train:\n",
    "    print(name)\n",
    "    print(len(np.load(name)[0]))\n",
    "\n",
    "# The count vectors have too many columns and need to be trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_columns(len, unique):\n",
    "    columns = []\n",
    "    for i in range(len):\n",
    "        columns.append(str(i + unique))\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = np.load('features_countvec/train_countvec_features_actor_1_name.npy')\n",
    "df_act_1 = pd.DataFrame(temp1, columns=create_columns(len(temp1[0]), 0))\n",
    "\n",
    "temp2 = np.load('features_countvec/train_countvec_features_actor_2_name.npy')\n",
    "df_act_2 = pd.DataFrame(temp2, columns=create_columns(len(temp2[0]), len(temp1[0])))\n",
    "\n",
    "temp3 = np.load('features_countvec/train_countvec_features_director_name.npy')\n",
    "df_dir = pd.DataFrame(temp3, columns=create_columns(len(temp3[0]), len(temp1[0]) + len(temp2[0])))\n",
    "\n",
    "temp4 = np.load('features_doc2vec/train_doc2vec_features_genre.npy')\n",
    "df_genre = pd.DataFrame(temp4, columns=create_columns(len(temp4[0]), len(temp1[0]) + len(temp2[0]) + 100))\n",
    "\n",
    "temp5 = np.load('features_doc2vec/train_doc2vec_features_plot_keywords.npy')\n",
    "df_keyword = pd.DataFrame(temp5, columns=create_columns(len(temp5[0]), len(temp1[0]) + len(temp2[0]) + 200))\n",
    "\n",
    "temp6 = np.load('features_fasttext/train_fasttext_title_embeddings.npy')\n",
    "df_title = pd.DataFrame(temp6, columns=create_columns(len(temp6[0]), len(temp1[0]) + len(temp2[0]) + 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.040870</td>\n",
       "      <td>-0.020972</td>\n",
       "      <td>-0.000291</td>\n",
       "      <td>-0.019807</td>\n",
       "      <td>-0.067842</td>\n",
       "      <td>-0.039268</td>\n",
       "      <td>0.021978</td>\n",
       "      <td>0.009322</td>\n",
       "      <td>-0.022309</td>\n",
       "      <td>-0.052090</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128962</td>\n",
       "      <td>0.005504</td>\n",
       "      <td>0.035380</td>\n",
       "      <td>0.077826</td>\n",
       "      <td>0.051705</td>\n",
       "      <td>-0.048289</td>\n",
       "      <td>-0.028773</td>\n",
       "      <td>-0.063556</td>\n",
       "      <td>-0.065825</td>\n",
       "      <td>-0.130789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.033925</td>\n",
       "      <td>0.020134</td>\n",
       "      <td>-0.035483</td>\n",
       "      <td>0.005658</td>\n",
       "      <td>-0.060051</td>\n",
       "      <td>-0.015003</td>\n",
       "      <td>-0.044098</td>\n",
       "      <td>-0.028774</td>\n",
       "      <td>0.066606</td>\n",
       "      <td>-0.019119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054433</td>\n",
       "      <td>0.067040</td>\n",
       "      <td>-0.082632</td>\n",
       "      <td>0.036925</td>\n",
       "      <td>-0.014433</td>\n",
       "      <td>0.011553</td>\n",
       "      <td>0.113548</td>\n",
       "      <td>0.011281</td>\n",
       "      <td>0.027964</td>\n",
       "      <td>0.026742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.107427</td>\n",
       "      <td>0.041082</td>\n",
       "      <td>1.065319</td>\n",
       "      <td>0.087488</td>\n",
       "      <td>0.233568</td>\n",
       "      <td>-0.097163</td>\n",
       "      <td>-0.085989</td>\n",
       "      <td>-0.001578</td>\n",
       "      <td>0.078709</td>\n",
       "      <td>-0.038434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040438</td>\n",
       "      <td>0.026457</td>\n",
       "      <td>0.021132</td>\n",
       "      <td>-0.044320</td>\n",
       "      <td>0.003424</td>\n",
       "      <td>-0.032042</td>\n",
       "      <td>-0.005082</td>\n",
       "      <td>0.018060</td>\n",
       "      <td>-0.056469</td>\n",
       "      <td>0.006051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.954659</td>\n",
       "      <td>-0.382909</td>\n",
       "      <td>0.102390</td>\n",
       "      <td>-0.118210</td>\n",
       "      <td>-0.026847</td>\n",
       "      <td>-0.015420</td>\n",
       "      <td>-0.038243</td>\n",
       "      <td>-0.019050</td>\n",
       "      <td>0.041273</td>\n",
       "      <td>0.030041</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050197</td>\n",
       "      <td>-0.031590</td>\n",
       "      <td>0.115097</td>\n",
       "      <td>0.080508</td>\n",
       "      <td>0.099152</td>\n",
       "      <td>-0.078682</td>\n",
       "      <td>-0.021129</td>\n",
       "      <td>0.071354</td>\n",
       "      <td>-0.057523</td>\n",
       "      <td>-0.012532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.039269</td>\n",
       "      <td>-0.068133</td>\n",
       "      <td>-0.053963</td>\n",
       "      <td>-0.056048</td>\n",
       "      <td>-0.171098</td>\n",
       "      <td>-0.109996</td>\n",
       "      <td>-0.184301</td>\n",
       "      <td>-0.695090</td>\n",
       "      <td>-0.328191</td>\n",
       "      <td>0.731292</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053631</td>\n",
       "      <td>-0.026796</td>\n",
       "      <td>0.047281</td>\n",
       "      <td>0.040197</td>\n",
       "      <td>0.020018</td>\n",
       "      <td>0.031986</td>\n",
       "      <td>-0.015604</td>\n",
       "      <td>-0.092784</td>\n",
       "      <td>0.124346</td>\n",
       "      <td>-0.061872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.040870 -0.020972 -0.000291 -0.019807 -0.067842 -0.039268  0.021978   \n",
       "1 -0.033925  0.020134 -0.035483  0.005658 -0.060051 -0.015003 -0.044098   \n",
       "2 -0.107427  0.041082  1.065319  0.087488  0.233568 -0.097163 -0.085989   \n",
       "3  0.954659 -0.382909  0.102390 -0.118210 -0.026847 -0.015420 -0.038243   \n",
       "4 -0.039269 -0.068133 -0.053963 -0.056048 -0.171098 -0.109996 -0.184301   \n",
       "\n",
       "          7         8         9  ...       290       291       292       293  \\\n",
       "0  0.009322 -0.022309 -0.052090  ... -0.128962  0.005504  0.035380  0.077826   \n",
       "1 -0.028774  0.066606 -0.019119  ...  0.054433  0.067040 -0.082632  0.036925   \n",
       "2 -0.001578  0.078709 -0.038434  ...  0.040438  0.026457  0.021132 -0.044320   \n",
       "3 -0.019050  0.041273  0.030041  ... -0.050197 -0.031590  0.115097  0.080508   \n",
       "4 -0.695090 -0.328191  0.731292  ... -0.053631 -0.026796  0.047281  0.040197   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0  0.051705 -0.048289 -0.028773 -0.063556 -0.065825 -0.130789  \n",
       "1 -0.014433  0.011553  0.113548  0.011281  0.027964  0.026742  \n",
       "2  0.003424 -0.032042 -0.005082  0.018060 -0.056469  0.006051  \n",
       "3  0.099152 -0.078682 -0.021129  0.071354 -0.057523 -0.012532  \n",
       "4  0.020018  0.031986 -0.015604 -0.092784  0.124346 -0.061872  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement PCA to cut down columns further\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n1 = 100\n",
    "pca = PCA(n_components=n1)\n",
    "\n",
    "df_list = [df_act_1, df_act_2, df_dir, df_genre, df_keyword, df_title]\n",
    "train_pre_data = pd.concat(df_list, axis=1)\n",
    "\n",
    "columns = []\n",
    "for i in range(n1):\n",
    "    columns.append(str(i))\n",
    "\n",
    "principalComponents = pca.fit_transform(train_pre_data)\n",
    "\n",
    "df_pca = pd.DataFrame(data=principalComponents, columns=columns)\n",
    "\n",
    "df_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_selection import RFE\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#selector = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=100, step=10)\n",
    "#test_x = selector.fit_transform(df_pca, train['imdb_score_binned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns = []\n",
    "#for i in range(100):\n",
    "#    columns.append(str(i))\n",
    "\n",
    "#df_selected_train = pd.DataFrame(data=test_x, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315\n"
     ]
    }
   ],
   "source": [
    "# Drop old columns and unnecessary columns\n",
    "titles = ['actor_1_name', 'actor_2_name', 'director_name', 'genres', 'plot_keywords', 'language', 'country', 'id',\n",
    "            'title_embedding', 'movie_title', 'actor_3_name', 'actor_3_facebook_likes']\n",
    "train_new = pd.concat([train.drop(columns=titles), df_pca], axis=1)\n",
    "\n",
    "print(len(train_new.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "content_rating\n",
       "R            1362\n",
       "PG-13        1039\n",
       "PG            458\n",
       "G              68\n",
       "Not Rated      27\n",
       "Unrated        19\n",
       "Approved       14\n",
       "X               9\n",
       "NC-17           3\n",
       "M               2\n",
       "Passed          2\n",
       "GP              1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use OHE\n",
    "train['content_rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "content_rating\n",
       "R           1362\n",
       "PG-13       1041\n",
       "PG           458\n",
       "G             69\n",
       "Unrated       46\n",
       "Approved      16\n",
       "X             12\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine ratings\n",
    "train.loc[train.content_rating == 'GP', 'content_rating'] = 'G'\n",
    "train.loc[train.content_rating == 'Passed', 'content_rating'] = 'Approved'\n",
    "train.loc[train.content_rating == 'NC-17', 'content_rating'] = 'X'\n",
    "train.loc[train.content_rating == 'Not Rated', 'content_rating'] = 'Unrated'\n",
    "train.loc[train.content_rating == 'M', 'content_rating'] = 'PG-13'\n",
    "\n",
    "train['content_rating'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "encoded = enc.fit_transform(train[['content_rating']])\n",
    "\n",
    "df_temp = pd.DataFrame(encoded.toarray(), columns=['Approved', 'G', 'PG', 'PG-13', 'R', 'Unrated', 'X'])\n",
    "\n",
    "train_final = pd.concat([train_new.drop(columns=['content_rating']), df_temp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_final['imdb_score_binned']\n",
    "X = train_final.drop(columns=['imdb_score_binned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply post processing, ie normalisation, standardisation\n",
    "# Remove outliers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#scaler = MinMaxScaler()\n",
    "scaler = StandardScaler()\n",
    "X_norm = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test data\n",
    "temp1_test = np.load('features_countvec/test_countvec_features_actor_1_name.npy')\n",
    "df_act_1_test = pd.DataFrame(temp1_test, columns=create_columns(len(temp1_test[0]), 0))\n",
    "\n",
    "temp2_test = np.load('features_countvec/test_countvec_features_actor_2_name.npy')\n",
    "df_act_2_test = pd.DataFrame(temp2_test, columns=create_columns(len(temp2_test[0]), len(temp1_test[0])))\n",
    "\n",
    "temp3_test = np.load('features_countvec/test_countvec_features_director_name.npy')\n",
    "df_dir_test = pd.DataFrame(temp3_test, columns=create_columns(len(temp3_test[0]), len(temp1_test[0]) + len(temp2_test[0])))\n",
    "\n",
    "temp4_test = np.load('features_doc2vec/test_doc2vec_features_genre.npy')\n",
    "df_genre_test = pd.DataFrame(temp4_test, columns=create_columns(len(temp4_test[0]), len(temp1_test[0]) + len(temp2_test[0]) + 100))\n",
    "\n",
    "temp5_test = np.load('features_doc2vec/test_doc2vec_features_plot_keywords.npy')\n",
    "df_keyword_test = pd.DataFrame(temp5_test, columns=create_columns(len(temp5_test[0]), len(temp1_test[0]) + len(temp2_test[0]) + 200))\n",
    "\n",
    "temp6_test = np.load('features_fasttext/test_fasttext_title_embeddings.npy')\n",
    "df_title_test = pd.DataFrame(temp6_test, columns=create_columns(len(temp6_test[0]), len(temp1_test[0]) + len(temp2_test[0]) + 300))\n",
    "\n",
    "#df_act_1_test = drop_col(df_act_1_test)\n",
    "#df_act_2_test = drop_col(df_act_2_test)\n",
    "#df_dir_test = drop_col(df_dir_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df_act_1_test, df_act_2_test, df_dir_test, df_genre_test, df_keyword_test, df_title_test]\n",
    "test_pre_data = pd.concat(df_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply fitted PCA to test data\n",
    "test_pcs = pca.transform(test_pre_data)\n",
    "\n",
    "columns = []\n",
    "for i in range(n1):\n",
    "    columns.append(str(i))\n",
    "\n",
    "df_pca_test = pd.DataFrame(data=test_pcs, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_test_100 = selector.transform(df_pca_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns = []\n",
    "#for i in range(100):\n",
    "#    columns.append(str(i))\n",
    "\n",
    "#df_selected_test = pd.DataFrame(data=x_test_100, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314\n"
     ]
    }
   ],
   "source": [
    "test_new = pd.concat([test.drop(columns=titles), df_pca_test], axis=1)\n",
    "\n",
    "print(len(test_new.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove low frequency ratings\n",
    "#count = test_new['content_rating'].value_counts()\n",
    "#test_new = test_new[~test_new['content_rating'].isin(count[count < 15].index)]  \n",
    "\n",
    "# Combine ratings\n",
    "test.loc[test.content_rating == 'GP', 'content_rating'] = 'G'\n",
    "test.loc[test.content_rating == 'Passed', 'content_rating'] = 'Approved'\n",
    "test.loc[test.content_rating == 'NC-17', 'content_rating'] = 'X'\n",
    "test.loc[test.content_rating == 'Not Rated', 'content_rating'] = 'Unrated'\n",
    "test.loc[test.content_rating == 'M', 'content_rating'] = 'PG-13'\n",
    "\n",
    "encoded = enc.transform(test[['content_rating']])\n",
    "\n",
    "df_temp = pd.DataFrame(encoded.toarray(), columns=['Approved', 'G', 'PG', 'PG-13', 'R', 'Unrated', 'X'])\n",
    "\n",
    "test_new = pd.concat([test_new.drop(columns='content_rating'), df_temp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm_test = scaler.transform(test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove_negative_features = ['num_critic_for_reviews', 'director_facebook_likes', 'actor_1_facebook_likes', 'facenumber_in_poster', \n",
    "#                            'average_degree_centrality', '0', '1', '3', '5', '6', '9', '10', '12', '13', '14', '15', \n",
    "#                            '16', '17', '19', '21', '23', '24', '25', '27', '28', '29', '30', '31', '33', '36', '37', '38', '44', \n",
    "#                            '47', '48', '50', '51', '54', '55', '58', '62', '63', '64', '66', '68', '72', '73', '74', '76', '77', \n",
    "#                            '79', '81', '82', '85', '88', '89', '90', '92', '93', '95', '96', '98', 'G', 'PG', 'R']\n",
    "\n",
    "#X_norm_test_dropped = pd.DataFrame(X_norm_test, columns=test_new.columns).drop(columns=remove_negative_features)\n",
    "\n",
    "#X_norm_dropped = pd.DataFrame(X_norm, columns=test_new.columns).drop(columns=remove_negative_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import GradientBoostingClassifier\n",
    "#GTB = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,\n",
    "#                                 max_depth=5, random_state=0).fit(X_norm, y)\n",
    "#y_GTB = GTB.predict(X_norm_test)\n",
    "#df_GTB = pd.DataFrame(y_GTB, columns=['imdb_score_binned'])\n",
    "#df_GTB.insert(0, 'id', range(1, len(df_GTB) + 1))\n",
    "#df_GTB['imdb_score_binned'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "imdb_score_binned\n",
       "2    569\n",
       "3    151\n",
       "4     19\n",
       "1     13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "XGB = XGBClassifier(max_depth=4, random_state=0).fit(X_norm, y)\n",
    "y_XGB = XGB.predict(X_norm_test)\n",
    "df_XGB = pd.DataFrame(y_XGB, columns=['imdb_score_binned'])\n",
    "df_XGB.insert(0, 'id', range(1, len(df_XGB) + 1))\n",
    "df_XGB['imdb_score_binned'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_XGB.to_csv('submission.csv', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
